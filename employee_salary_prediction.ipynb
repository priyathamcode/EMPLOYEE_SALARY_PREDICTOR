{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pKtfl5cJ2xbQ",
        "outputId": "19d9b7a4-0f5d-4ef7-8949-f43c4b286f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit pandas scikit-learn pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62L6KvSz2enr",
        "outputId": "2fb7e01a-c946-4dbe-826b-e552e0b09a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# --- Page Configuration ---\n",
        "st.set_page_config(\n",
        "    page_title=\"Income Prediction App 💰\",\n",
        "    page_icon=\"🤖\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\",\n",
        ")\n",
        "\n",
        "# --- Data Loading and Caching ---\n",
        "@st.cache_data\n",
        "def load_data(file_path):\n",
        "    \"\"\"Loads, cleans, and prepares the UCI Adult dataset.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Clean column names and string data\n",
        "    df.columns = df.columns.str.strip()\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        df[col] = df[col].str.strip()\n",
        "\n",
        "    # Remove the 'fnlwgt' column as it's not a predictive feature\n",
        "    df.drop('fnlwgt', axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "    # Replace '?' with NaN and drop rows with any missing values\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Convert target variable 'income' to binary\n",
        "    df['income'] = df['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
        "    return df\n",
        "\n",
        "# --- Model Training and Caching ---\n",
        "@st.cache_resource\n",
        "def train_model(df):\n",
        "    \"\"\"Preprocesses data and trains a Logistic Regression model.\"\"\"\n",
        "    X = df.drop('income', axis=1)\n",
        "    y = df['income']\n",
        "\n",
        "    # Identify categorical and numerical features\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns\n",
        "    numerical_features = X.select_dtypes(include=np.number).columns\n",
        "\n",
        "    # Create a robust preprocessing pipeline\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numerical_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Create the full model pipeline\n",
        "    model_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
        "    ])\n",
        "\n",
        "    # Split data and train the model\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    return model_pipeline, X_test, y_test\n",
        "\n",
        "# --- Main Application UI ---\n",
        "st.title(\"Income Level Prediction App 💰\")\n",
        "st.write(\n",
        "    \"This app predicts whether an individual's annual income is above or below $50K \"\n",
        "    \"based on their demographic and employment data.\"\n",
        ")\n",
        "st.write(\"---\")\n",
        "\n",
        "# Load data and train the model\n",
        "try:\n",
        "    df = load_data('adult 3.csv')\n",
        "    model, X_test, y_test = train_model(df)\n",
        "except FileNotFoundError:\n",
        "    st.error(\"Error: `adult 3.csv` not found. Please place the dataset in the same directory.\")\n",
        "    st.stop()\n",
        "\n",
        "# --- Sidebar for User Input ---\n",
        "st.sidebar.header(\"👤 User Input Features\")\n",
        "\n",
        "def user_input_features(data):\n",
        "    \"\"\"Creates sidebar widgets for user input and returns a DataFrame.\"\"\"\n",
        "    inputs = {}\n",
        "    for col in data.drop('income', axis=1).columns:\n",
        "        if data[col].dtype == 'object':\n",
        "            options = sorted(data[col].unique())\n",
        "            inputs[col] = st.sidebar.selectbox(f\"Select {col.replace('-', ' ').title()}\", options)\n",
        "        else:\n",
        "            min_val, max_val = int(data[col].min()), int(data[col].max())\n",
        "            default_val = int(data[col].median()) # Use median for a more robust default\n",
        "            inputs[col] = st.sidebar.slider(f\"Select {col.replace('-', ' ').title()}\", min_val, max_val, default_val)\n",
        "    return pd.DataFrame([inputs])\n",
        "\n",
        "input_df = user_input_features(df)\n",
        "\n",
        "# --- Prediction and Output ---\n",
        "st.header(\"🔮 Prediction\")\n",
        "col1, col2 = st.columns([1, 2])\n",
        "\n",
        "with col1:\n",
        "    st.write(\"**Your Selections:**\")\n",
        "    st.dataframe(input_df.T.rename(columns={0: 'Value'}), use_container_width=True)\n",
        "\n",
        "with col2:\n",
        "    if st.button(\"Predict Income\", type=\"primary\", use_container_width=True):\n",
        "        prediction = model.predict(input_df)[0]\n",
        "        prediction_proba = model.predict_proba(input_df)[0]\n",
        "\n",
        "        st.subheader(\"Prediction Result\")\n",
        "        income_level = \">$50K\" if prediction == 1 else \"<=$50K\"\n",
        "        confidence = prediction_proba[prediction]\n",
        "\n",
        "        if income_level == \">$50K\":\n",
        "            st.success(f\"**Predicted Income:** {income_level}\", icon=\"🎉\")\n",
        "        else:\n",
        "            st.info(f\"**Predicted Income:** {income_level}\", icon=\"💵\")\n",
        "\n",
        "        st.metric(label=\"**Confidence Score**\", value=f\"{confidence:.2%}\")\n",
        "\n",
        "        st.write(\"**Prediction Probabilities:**\")\n",
        "        st.progress(prediction_proba[1], text=f\"Probability of earning >$50K\")\n",
        "\n",
        "st.write(\"---\")\n",
        "\n",
        "# --- Model Performance Metrics ---\n",
        "with st.expander(\"📊 See Model Performance Metrics\"):\n",
        "    st.write(\n",
        "        \"These metrics evaluate the model's performance on a separate test set \"\n",
        "        \"that it did not see during training.\"\n",
        "    )\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and display metrics\n",
        "    m1, m2, m3, m4 = st.columns(4)\n",
        "    m1.metric(\"Accuracy\", f\"{accuracy_score(y_test, y_pred):.2%}\")\n",
        "    m2.metric(\"Precision\", f\"{precision_score(y_test, y_pred):.2%}\")\n",
        "    m3.metric(\"Recall\", f\"{recall_score(y_test, y_pred):.2%}\")\n",
        "    m4.metric(\"F1-Score\", f\"{f1_score(y_test, y_pred):.2%}\")\n",
        "\n",
        "# --- Data Explorer ---\n",
        "with st.expander(\"📂 Explore the Training Dataset\"):\n",
        "    st.write(\"View, sort, and filter the raw data used for training.\")\n",
        "    st.dataframe(df, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUqL_dA43XbM",
        "outputId": "469b51a3-1d83-482b-c31b-69a90bac80a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "🎉 Your Streamlit app is live! Click the link: NgrokTunnel: \"https://4a10ba0134b1.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# --- PASTE YOUR NGROK AUTHTOKEN HERE ---\n",
        "AUTHTOKEN = \"YOUR_AUTHTOKEN_HERE\"\n",
        "\n",
        "# Configure ngrok with your authtoken\n",
        "!ngrok config add-authtoken {AUTHTOKEN}\n",
        "\n",
        "# Terminate any existing tunnels from this process to prevent conflicts\n",
        "ngrok.kill()\n",
        "\n",
        "# Start a new tunnel and launch the Streamlit app\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"🎉 Your Streamlit app is live! Click the link: {public_url}\")\n",
        "!streamlit run app.py --server.port 8501 &>/dev/null&"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
